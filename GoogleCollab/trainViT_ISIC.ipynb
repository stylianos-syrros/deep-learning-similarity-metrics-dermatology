{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4Wvv6Kbs8fP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import timm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "\n",
        "# Εισαγωγή του PyTorch XLA (TPU)\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "# Ορισμός του Logger\n",
        "logging.basicConfig(filename=r'D:\\Diploma\\ISIC_log\\training_from_start_log.log', level=logging.INFO,\n",
        "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
        "\n",
        "# Έλεγχος για TPU\n",
        "device = xm.xla_device()\n",
        "print(\"Using TPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ορισμός των μετασχηματισμών\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.6459899, 0.52058024, 0.51453681], std=[0.14522511, 0.15518147, 0.16543107])\n",
        "])\n",
        "\n",
        "# Φόρτωση των δεδομένων από τους φακέλους\n",
        "train_dir = r\"D:\\Diploma\\datasets\\processed_ISIC_Dataset\\train\"\n",
        "test_dir = r\"D:\\Diploma\\datasets\\processed_ISIC_Dataset\\test\"\n",
        "\n",
        "full_train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Δημιουργία των indices για κάθε κατηγορία στο training set\n",
        "train_indices = {cls: [] for cls in range(3)}\n",
        "for idx, (_, label) in enumerate(full_train_dataset):\n",
        "    train_indices[label].append(idx)\n",
        "\n",
        "# Επιλογή του 10% για validation και το υπόλοιπο 90% για training από κάθε κατηγορία\n",
        "val_indices = []\n",
        "train_indices_final = []\n",
        "for cls in range(3):\n",
        "    cls_train_indices = train_indices[cls]\n",
        "    print(f'Total indices for class {cls}: {len(cls_train_indices)}')\n",
        "    cls_train, cls_val = train_test_split(cls_train_indices, test_size=0.1, random_state=42)\n",
        "    print(f'Class {cls}: {len(cls_train)} training indices, {len(cls_val)} validation indices')\n",
        "    train_indices_final.extend(cls_train)\n",
        "    val_indices.extend(cls_val)\n",
        "\n",
        "train_dataset = Subset(full_train_dataset, train_indices_final)\n",
        "val_dataset = Subset(full_train_dataset, val_indices)\n"
      ],
      "metadata": {
        "id": "CEuWuJURuz4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Δημιουργία DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Εκτύπωση του πλήθους εικόνων στα datasets\n",
        "print(f'Training dataset size: {len(train_dataset)} images')\n",
        "print(f'Validation dataset size: {len(val_dataset)} images')\n",
        "print(f'Test dataset size: {len(test_dataset)} images')\n",
        "\n",
        "# Εκτύπωση του πλήθους των κατηγοριών\n",
        "print(f'Number of classes: {len(full_train_dataset.classes)}')"
      ],
      "metadata": {
        "id": "xx-K1B-Cu2Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Φάκελος αποθήκευσης μοντέλων\n",
        "model_dir = r\"D:\\Diploma\\ViT_models_ISIC\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Φόρτωση του ViT μοντέλου στον TPU\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=3).to(device)\n"
      ],
      "metadata": {
        "id": "MPjgOZjLvWKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ορισμός του loss function και του optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Εκπαίδευση του μοντέλου\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25):\n",
        "    start_time = time.time()\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        epoch_start_time = time.time()  # Έναρξη του timer για κάθε epoch\n",
        "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "        logging.info(f\"Epoch {epoch}/{num_epochs}\")\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Εκπαίδευση του μοντέλου\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "        # Αξιολόγηση του μοντέλου στο validation set\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_corrects = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = val_corrects.double() / len(val_loader.dataset)\n",
        "\n",
        "        epoch_duration = time.time() - epoch_start_time  # Διάρκεια του epoch\n",
        "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
        "        print(f'Epoch duration: {epoch_duration:.2f} seconds')\n",
        "\n",
        "        logging.info(f'Epoch {epoch}/{num_epochs} completed')\n",
        "        logging.info(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "        logging.info(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
        "        logging.info(f'Epoch duration: {epoch_duration:.2f} seconds')\n",
        "\n",
        "        # Αποθήκευση του μοντέλου για κάθε epoch\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'epoch_val_loss': val_loss,  # Τρέχουσα απόδοση του μοντέλου\n",
        "            'epoch_val_acc': val_acc,    # Τρέχουσα ακρίβεια του μοντέλου\n",
        "            'best_val_loss': best_val_loss,\n",
        "        }, os.path.join(model_dir, f'vit_model_epoch_{epoch}.pth'))\n",
        "        logging.info(f'Model for epoch {epoch} saved')\n",
        "\n",
        "        # Αποθήκευση του καλύτερου μοντέλου\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'best_val_loss': best_val_loss,\n",
        "            }, os.path.join(model_dir, 'best_vit_model.pth'))\n",
        "            print('Best model saved')\n",
        "            logging.info('Best model saved')\n",
        "\n",
        "\n",
        "    total_duration = time.time() - start_time  # Συνολική διάρκεια εκπαίδευσης\n",
        "    print(f'Best val Loss: {best_val_loss:.4f}')\n",
        "    print(f'Total training duration: {total_duration:.2f} seconds')\n",
        "    logging.info(f'Best val Loss: {best_val_loss:.4f}')\n",
        "    logging.info(f'Total training duration: {total_duration:.2f} seconds')\n",
        "\n",
        "# Κλήση της συνάρτησης εκπαίδευσης\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25)\n"
      ],
      "metadata": {
        "id": "wgVdd2hqvTDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Τελική αξιολόγηση στο test set\n",
        "checkpoint = torch.load(os.path.join(model_dir, 'best_vit_model.pth'))\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Αξιολόγηση του μοντέλου στο test set\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    corrects = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            corrects += torch.sum(preds == labels.data)\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    test_acc = corrects.double() / len(test_loader.dataset)\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
        "    logging.info(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Κλήση της συνάρτησης αξιολόγησης\n",
        "evaluate_model(model, test_loader, criterion)"
      ],
      "metadata": {
        "id": "aOWfXPx3v9Wq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}